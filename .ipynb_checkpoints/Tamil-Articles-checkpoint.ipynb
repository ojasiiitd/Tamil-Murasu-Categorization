{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28569707-85c8-404b-a338-67f0845731fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager as fm\n",
    "from collections import Counter\n",
    "\n",
    "import re\n",
    "from tamil import utf8\n",
    "from indicnlp import common\n",
    "from indicnlp import loader\n",
    "from indicnlp.tokenize import indic_tokenize\n",
    "from indicnlp.transliterate.unicode_transliterate import ItransTransliterator\n",
    "\n",
    "INDIC_NLP_RESOURCES=r\"./indic_nlp_resources/\"\n",
    "# Export the path to the Indic NLP Resources directory programmatically\n",
    "common.set_resources_path(INDIC_NLP_RESOURCES)\n",
    "# Initialize the Indic NLP library\n",
    "loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6108e972-3ff0-440c-99e4-088e006eeb32",
   "metadata": {},
   "source": [
    "# Working On the Model ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550f14d1-f8c9-4f7f-a4ab-782ed182ca56",
   "metadata": {},
   "source": [
    "## Reading the Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20498ebc-a1a1-44dc-86f7-79583e3355a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_id</th>\n",
       "      <th>news_date</th>\n",
       "      <th>news_category</th>\n",
       "      <th>news_title</th>\n",
       "      <th>news_article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39141</th>\n",
       "      <td>39616</td>\n",
       "      <td>1/31/2013 2:41:26 PM</td>\n",
       "      <td>தமிழகம்</td>\n",
       "      <td>ஆண்டுக்கான கூட்டம் : சட்டசபை நாளை கூடுகிறது ; ...</td>\n",
       "      <td>சென்னை : தமிழக சட்டசபை நாளை காலை 10 மணிக்கு கூ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84094</th>\n",
       "      <td>84826</td>\n",
       "      <td>11/25/2015 3:04:47 PM</td>\n",
       "      <td>தமிழகம்</td>\n",
       "      <td>திமுக சார்பில் வெள்ளத்தால் பாதித்த 1500 பேருக்...</td>\n",
       "      <td>வேளச்சேரி : திமுக சார்பில் வெள்ளத்தால் பாதிக்க...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65447</th>\n",
       "      <td>66134</td>\n",
       "      <td>11/20/2014 2:19:20 PM</td>\n",
       "      <td>சினிமா(ரீல்மா)</td>\n",
       "      <td>வாலிபரை மணக்க விரும்புகிறார் 63 வயதாகும் இந்தி...</td>\n",
       "      <td>மும்பை : 1970களில் பாலிவுட் படவுலகை கலக்கியவர்...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45361</th>\n",
       "      <td>45900</td>\n",
       "      <td>7/10/2013 2:03:26 PM</td>\n",
       "      <td>இந்தியா</td>\n",
       "      <td>தலைநகர் டெல்லியை கலக்கும் கிளினிக் எல்லா நோய்க...</td>\n",
       "      <td>புதுடெல்லி : நோயாளிகளின் உடலில் பிளேடால் கீறி ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34490</th>\n",
       "      <td>34913</td>\n",
       "      <td>10/16/2012 5:52:06 PM</td>\n",
       "      <td>ஆன்மீகம்</td>\n",
       "      <td>நலங்கள் அள்ளி தரும் நவராத்திரி</td>\n",
       "      <td>சிவனுக்கு உகந்தது சிவராத்திரி . தம் தேவியர்க்க...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       news_id              news_date   news_category  \\\n",
       "39141    39616   1/31/2013 2:41:26 PM         தமிழகம்   \n",
       "84094    84826  11/25/2015 3:04:47 PM         தமிழகம்   \n",
       "65447    66134  11/20/2014 2:19:20 PM  சினிமா(ரீல்மா)   \n",
       "45361    45900   7/10/2013 2:03:26 PM         இந்தியா   \n",
       "34490    34913  10/16/2012 5:52:06 PM        ஆன்மீகம்   \n",
       "\n",
       "                                              news_title  \\\n",
       "39141  ஆண்டுக்கான கூட்டம் : சட்டசபை நாளை கூடுகிறது ; ...   \n",
       "84094  திமுக சார்பில் வெள்ளத்தால் பாதித்த 1500 பேருக்...   \n",
       "65447  வாலிபரை மணக்க விரும்புகிறார் 63 வயதாகும் இந்தி...   \n",
       "45361  தலைநகர் டெல்லியை கலக்கும் கிளினிக் எல்லா நோய்க...   \n",
       "34490                     நலங்கள் அள்ளி தரும் நவராத்திரி   \n",
       "\n",
       "                                            news_article  \n",
       "39141  சென்னை : தமிழக சட்டசபை நாளை காலை 10 மணிக்கு கூ...  \n",
       "84094  வேளச்சேரி : திமுக சார்பில் வெள்ளத்தால் பாதிக்க...  \n",
       "65447  மும்பை : 1970களில் பாலிவுட் படவுலகை கலக்கியவர்...  \n",
       "45361  புதுடெல்லி : நோயாளிகளின் உடலில் பிளேடால் கீறி ...  \n",
       "34490  சிவனுக்கு உகந்தது சிவராத்திரி . தம் தேவியர்க்க...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tamil = pd.read_csv(\"./tamilmurasu_data/tamil_news_cleaned.csv\", encoding='utf-8')\n",
    "df_tamil.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bc5849-1a2c-4557-a0a5-7660c47f39a6",
   "metadata": {},
   "source": [
    "## Making all words/sentences lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79b77d2f-b913-4dbe-8601-e1d721e84cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing as\n",
    "# [ [article1] , [article2]  ... ]\n",
    "\n",
    "articles_sentences_combined = []\n",
    "for i in range(len(df_tamil)):\n",
    "    pattern = r\"[\\xa0.,?!:/@#$%^&*(){}<>-_\\+=\\[\\]\\d’‘\\\"'\\\\]\"  # Matches symbols and digits \\xa0\n",
    "    cur_article = re.sub(pattern, '', df_tamil['news_article'][i])\n",
    "    articles_sentences_combined.append(cur_article)\n",
    "#     if i == 1000:\n",
    "#         break\n",
    "\n",
    "# print(df_tamil['news_article'][823][200:])\n",
    "# re.sub(pattern, '', df_tamil['news_article'][823][200:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77049e1e-408f-440e-a8ee-319affc83d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "திண்டுக்கல்  ஆத்தூர் தொகுதி தேமுதிக வேட்பாளர் பாலசுப்பிரமணி நேற்று வேட்புமனு தாக்கல் செய்ய திண்டுக்கல் கலெக்டர் ஆபீசுக்கு வந்தார்  அவரிடம் உச்சகட்ட பரபரப்பு  அதிமுக மாவட்ட செயலாளர் நத்தம் விசுவநாதன்  மாவட்ட அவைத்தலைவர் சீனிவாசனும் உடன் வந்தனர்  வாட்ச்சை திருப்பி திருப்பி பார்த்துக் கொண்டே தேர்தல் அதிகாரி முருகவேலின் அறைக்குள் ஓடினார் பாலசுப்பிரமணி  வாங்கிப் பார்த்த அதிகாரிக்கு அதிர்ச்சி  என்னங்க   வெறும் படிவத்தை கொடுக்கறீங்க  நிரப்பவில்லையா   என்றார்  ஒரு மணி வரைதான் நல்ல நேரம்னாங்க  மொதல்ல வாங்கிடுங்க  அப்புறம் நிரப்புறேன் என்றார் பாலசுப்பிரமணி  நிரப்பாத படிவத்தை வாங்க முடியாது கறாராக கூறிவிட்டார் அதிகாரி  வாசல் பகுதியில் அறைக்கு சென்றனர்  பூர்த்தி செய்ய மணி நேரம் ஆனது  தாக்கல் செய்துவிட்டு சென்றார்  http    election  dinakaran  com \n"
     ]
    }
   ],
   "source": [
    "print(articles_sentences_combined[3944])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ea108d0-8641-476f-8408-41c93c872912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17717464 579080\n"
     ]
    }
   ],
   "source": [
    "# storing vocabulary by removing repeated words\n",
    "\n",
    "tamil_repeating_vocab = []\n",
    "for i,cur_article in enumerate(articles_sentences_combined):\n",
    "    cur_words = cur_article.split()\n",
    "    tamil_repeating_vocab.extend(cur_words)\n",
    "\n",
    "tamil_vocab = list(set(tamil_repeating_vocab))\n",
    "\n",
    "print(len(tamil_repeating_vocab) , len(tamil_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe577fb-c66d-4c35-be3c-a339b3e84427",
   "metadata": {},
   "source": [
    "# Converting data into vectors using different methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64c1f3a-286f-40ae-bce1-b1826004dd4f",
   "metadata": {},
   "source": [
    "## using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff187576-dbae-47b1-877a-876e571b072e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# trying sklearn countvectorizer on tamil dataset\n",
    "bag_tamil_words = CountVectorizer()\n",
    "tamil_count_vecs = bag_tamil_words.fit_transform(articles_sentences_combined).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f249a47-01c5-4223-bbd2-735f0c2404d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aaaoe' 'aai' 'aaisite' ... 'ஹஸரங' 'ஹஸரத' 'ஹஹ']\n",
      "80\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(bag_tamil_words.get_feature_names_out())\n",
    "print(sum(list(tamil_count_vecs[223])))\n",
    "tamil_count_vecs[223]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c0dac4-3110-468f-94ce-856bf91ee07f",
   "metadata": {},
   "source": [
    "## using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fc6cb43-7178-496b-930a-63b57afa5e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# trying sklearn TfidfVectorizer on tamil dataset\n",
    "tfidf_tamil_words = TfidfVectorizer()\n",
    "tamil_tfidf_vecs = tfidf_tamil_words.fit_transform(articles_sentences_combined).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20f158d5-b4dd-4875-a265-57c4aad49291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aaaoe' 'aai' 'aaisite' ... 'ஹஸரங' 'ஹஸரத' 'ஹஹ']\n",
      "13295\n",
      "4.004336372491501\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tfidf_tamil_words.get_feature_names_out())\n",
    "print(len(tfidf_tamil_words.get_feature_names_out()))\n",
    "print(sum(list(tamil_tfidf_vecs[4383])))\n",
    "tamil_tfidf_vecs[4383]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca55c0ca-028c-4ff8-b654-ed78914734a9",
   "metadata": {},
   "source": [
    "## Continuous Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728374e0-d3db-49a8-9c4f-4078faccef15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f333998-c331-4de9-9f6f-8b74ca046cec",
   "metadata": {},
   "source": [
    "# Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d0442e0-5b60-46ce-b9de-251d5576e2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Categories: [ 1  2  7 13  8 11  3 12  5  0  4  6  9 10 14]\n",
      "Category Mapping: {'ஆன்மீகம்': 0, 'இந்தியா': 1, 'உலகம்': 2, 'கல்வி': 3, 'குற்றம்': 4, 'சினிமா(ரீல்மா)': 5, 'தமிழகம்': 6, 'தலையங்கம்': 7, 'தொழில்': 8, 'மருத்துவம்': 9, 'மர்மம்': 10, 'மாவட்ட மசாலா': 11, 'விளையாட்டு': 12, 'வேலைவாய்ப்பு': 13, 'ஸ்டேட் எக்ஸ்பிரஸ்': 14}\n"
     ]
    }
   ],
   "source": [
    "# encoding the 15 unique categories\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# tamil news categories\n",
    "categories = list(df_tamil['news_category'])\n",
    "\n",
    "# Initialize and fit the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "target_vectors = label_encoder.fit_transform(categories)\n",
    "\n",
    "print(\"Encoded Categories:\", target_vectors)\n",
    "print(\"Category Mapping:\", dict(zip(label_encoder.classes_, range(len(label_encoder.classes_)))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1d4f308-e7e3-400d-b624-f3dc2304bc72",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [126746, 15]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m target_vectors \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39mfit_transform(categories)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Split data into train/test\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(tamil_count_vecs, target_vectors, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Train a model\u001b[39;00m\n\u001b[0;32m     16\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegression()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2559\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2557\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2559\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2561\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   2562\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2563\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m   2564\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:443\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \n\u001b[0;32m    426\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;124;03m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    442\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 443\u001b[0m check_consistent_length(\u001b[38;5;241m*\u001b[39mresult)\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    400\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [126746, 15]"
     ]
    }
   ],
   "source": [
    "# training a very basic model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Example: Using Label Encoding\n",
    "categories = list(set(df_tamil['news_category']))\n",
    "label_encoder = LabelEncoder()\n",
    "target_vectors = label_encoder.fit_transform(categories)\n",
    "\n",
    "# Split data into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(tamil_count_vecs, target_vectors, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
